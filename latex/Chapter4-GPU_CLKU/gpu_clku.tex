\chapter{GPU and Clock Unit design}

TODO: intro chaptitre ici

\section{GPU}
The GPU bears its name rather badly because it is not really programmable. This unit provides a 
graphic memory and the tools to draw patterns, called masks of 8x8 pixels. The writing in this 
memory is done from the beta machine (the CPU) through the instruction store (ST). The specific way 
of addressing the memory and the structure of the commands, passed through the data line of the 
store, are described later. As far as the colors are concerned, it has been decided to work with 
12bit RGB colors, that is to say 4 bits per color.

In addition to this, the GPU also provides the HDMI controller. This controller simply reads the 
graphics memory in a loop and draws its content on the screen. The controller can thus handle a 
16:9 screen with a resolution of 848x480 pixels and a refresh rate of 60Hz. The protocol used is 
the VESA 848x480, it is described later. 

Before moving on to the description of the different modules making up the GPU, a description of 
how the screen and the masks are interpreted by the GPU is done. The VESA protocol is also detailed.

\subsection{Screen and tiles representation}

As said before, the masks are 8x8 pixels and the goal is to be able to apply them to the screen. 
The screen is therefore naturally divided into a set of 8x8 pixel squares which are called tiles. 
In memory, the idea is that there are 3 sub-memories whose words contain a color of the three 
primary colors (red, green or blue) of a whole tile. A tile corresponding to 64 pixels and a 
primary color being coded on 4 bits, it gives words of 256 bits. Then, by dividing the dimensions 
of the screen (848x480 pixels) by 8, we find that 106x60 tiles, so 6360 are enough to represent 
the screen. In order not to use too much memory, it is decided to use 72x54 tiles. This corresponds 
to the largest integer size allowing a 4:3 ratio with a maximum use of 4096 tiles.  It is decided 
to limit to 4096 tiles because to use 6360 tiles it would be necessary to have a memory with 8192 
words, which would use too much memory unnecessarily. The useful screen is centered in the physical 
screen. Figure \ref{fig:gpu/screen_size} summarizes all this.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Chapter4-GPU_CLKU/res/screen_size}
    \caption{Useful screen area in the physical screen}
    \label{fig:gpu/screen_size}
\end{figure}

The problem with putting all tiles in a single memory like this is that only one tile is accessible 
at a time. This means that a mask can only be applied to one tile. This is a pity because it 
prevents the mask from being drawn anywhere on the screen. Indeed, the mask cannot for example be 
drawn between two tiles as shown in Figure \ref{fig:gpu/mask_2tiles}.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/mask_2tiles}
    \caption{Mask overlapping two tiles}
    \label{fig:gpu/mask_2tiles}
\end{figure}

When such a placement of the mask takes place, what actually happens is a tile is chosen first. And 
then an offset in pixels is added to the mask. In the example in Figure, the mask has a positive 
offset of N pixels with respect to Tile 1. The idea is then to allow a mask to have an offset 
ranging from 0 to 7 depending on the abscissa and ordinate. It is not useful to go further than 7 
as this corresponds to placing the mask at the next tile. To be able to apply the mask, it is 
therefore necessary to be able to load four tiles. The first one being the one chosen to draw the 
mask in (x, y), the others being those in (x + 1, y), (x, y + 1) and (x + 1, y + 1). A naive 
solution to load these four tiles would be to have a memory for each tile. However, this has two 
problems. The first is that this is impossible for the Cyclone V. Indeed, it was seen earlier that 
the Cyclone V has just over 500 M10K memory blocks. However, to represent all the tiles, we would 
need 3888 memories because the definition of a memory must use at least one whole M10K, which is 
simply impossible. 

Another way is to try to divide the set of tiles into four groups. These four groups should be 
distributed on the screen in such a way that the placement of a mask loads 4 tiles of different 
groups each time. If one thinks about it, it is possible to convince itself that a simple paving 
of 4 colors allows this (a color represents a group). Figure \ref{fig:gpu/screen_tiling} shows such 
a tiling. 

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/screen_tiling}
    \caption{Screen tiling}
    \label{fig:gpu/screen_tiling}
\end{figure}

And the different cases possible by choosing four tiles in the way explained earlier, i.e. one 
tile, the one to the right of it, the one below it and the one at the bottom right are shown 
Figure \ref{fig:gpu/screen_tiling_cases}. It can be seen that in each case, a group is present only 
once, which validates the possibility of representing all tiles in four distinct memories.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/screen_tiling_cases}
    \caption{Screen tiling selection cases}
    \label{fig:gpu/screen_tiling_cases}
\end{figure}

\subsection{Mask representation}

A mask has the same dimensions as a tile but does not have the same content. Indeed, a mask can 
contain four different values. The first value is keep, corresponding to a 0 in the mask. This 
value means that no modification will be made to the pixel screen targeted by this position in the 
mask. Then there is the set primary, corresponding to the value 1 which will set the pixel at this 
location to the primary color which will be defined in the set instruction, we will come back to 
this later. When the value is 2, it is then a so-called secondary color that is applied. And 
finally, the value 3 corresponds to a reset, the pixel then becomes black. Each of these values 
can therefore be represented on 2bits. Table \ref{tab:mask_op} summarizes the possible operations
of a mask. 

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|}
    \hline
    \rowcolor[HTML]{DAE8FC} 
    \multicolumn{1}{|c|}{\cellcolor[HTML]{DAE8FC}\textbf{Mask Operation}} & \textbf{Mask Value} \\ \hline
    Keep                                                                  & 0b00                \\ \hline
    Set primary                                                           & 0b01                \\ \hline
    Set secondary                                                         & 0b10                \\ \hline
    Reset                                                                 & 0b11                \\ \hline
    \end{tabular}
    \caption{Mask operations}
    \label{tab:mask_op}
\end{table}

In terms of representation, a mask is a simple vector of 8x8x2 (128) bits. Its LSB corresponds to 
the upper left corner of the mask and its MSB corresponds to the lower right corner of the mask. 
This correspondence is shown in Figure \ref{fig:gpu/mask_vector}.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/mask_vector}
    \caption{Mask vector representation}
    \label{fig:gpu/mask_vector}
\end{figure}

\subsection{Using the GPU}

As introduced, to use the GPU, it is necessary to use the store instruction from the CPU. But the 
address and data must be correctly formatted. For the address, it must start with 0b10 as seen in 
the chapter on the CPU (so that the addressed unit is the GPU). Then, it was decided to make the 
address natural, that is to say that it is 
readable without any conversion. The address therefore contains the exact pixel position where 
a mask should be applied. A pixel being located by four variables: block\_x, block\_y (corresponding 
to the tile), off\_x and off\_y (corresponding to the offset from the tile), these four variables 
are directly present in the address. The format of the address is explained in 
Figure \ref{fig:gpu/store_address}.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/store_address}
    \caption{Store instruction address}
    \label{fig:gpu/store_address}
\end{figure}

Concerning data, it must contain the mask identifier and the values of the two colors. As a color is 
represented on 12 bits and a word on the CPU is represented on 32 bits, 8 bits remain for the mask.  
The GPU can therefore support 256 masks. The data format is detailed in 
Figure \ref{fig:gpu/store_data}.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/store_data}
    \caption{Store instruction data}
    \label{fig:gpu/store_data}
\end{figure}

\subsection{VESA protocol}

The VESA protocol works exactly like the VGA protocol. That is, four signals are present. On the 
one hand there is the 24 bit color signal (8 bits for each primary color), the vertical and 
horizontal synchronization signals and the display enable signal. The synchronization signals 
inform the screen of the end of a line for horizontal synchronization and the end of a frame (all 
the lines on a screen) for vertical synchronization. Between two horizontal synchronization 
signals, several things happen. First, there is a pause just after the signal. This time is called 
horizontal back porch. Then, after this pause the colors are sent, the value must be maintained for 
a certain time to fix a pixel. All the pixels of the line are assigned one after the other, in 
burst. Of course there are specific timing criteria that must be met for this to work, this is 
discussed next. After sending all the colors, a new pause time takes place, called horizontal front 
porch. And finally, after this pause, a new horizontal synchronization signal is sent. For the 
frames, it's the same. Before the frame, there is a pause (vertical front porch) followed by the 
vertical synchronization followed by the vertical back porch. Note that the horizontal and vertical 
synchronizations are independent, so both must be evaluated at each moment. When no pause or 
synchronization occurs, either horizontal or vertical, the display is said to be enable. The 
display enable signal is then high and the colors are actually used for the pixels. Outside this 
condition, the color signal can be set to any value and is not listened to. 

The operation of the protocol is shown in Figure \ref{fig:gpu/screen_vesa}. The legend and length
of the signals are available in Table \ref{tab:gpu/vesa}. In this figure, 
the protocol is described in relation to the pixels, and therefore the position on the screen. As 
the screen only includes the pixels of the region where display enable is high, the frame shown is 
a virtual screen allowing the schematic. The description is made in relation to the pixels because 
it is easier to imagine but also to implement. Indeed, as shown later in this report, pixel 
counters are sufficient to implement this protocol. Then, it is enough to fix the good clock 
frequency so that the timings of each pixel are respected. For VESA 848x480, a clock of 33.750MHz
is used. Figure \ref{fig:gpu/vesa_signals} shows the value of the signals according to the position
on the screen.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Chapter4-GPU_CLKU/res/screen_vesa}
    \caption{VESA virtual screen schematic}
    \label{fig:gpu/screen_vesa}
\end{figure}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|}
    \hline
    \rowcolor[HTML]{DAE8FC} 
    \textbf{Signal} & \textbf{Complete name}    & \multicolumn{1}{l|}{\cellcolor[HTML]{DAE8FC}\textbf{Length (pixels)}} \\ \hline
    HFP             & Horizontal Front Porch    & 16                                                                    \\ \hline
    HSYNC           & Horizontal Sync           & 112                                                                   \\ \hline
    HBP             & Horizontal Back Porch     & 112                                                                   \\ \hline
    HDEN            & Horizontal Display Enable & 848                                                                   \\ \hline
    VFP             & Vertical Front Porch      & 6                                                                     \\ \hline
    VSYNC           & Vertical Sync             & 8                                                                     \\ \hline
    VBP             & Vertical Back Porch       & 23                                                                    \\ \hline
    VDEN            & Vertical Display Enable   & 480                                                                   \\ \hline
    \end{tabular}
    \caption{VESA 848x480 counts}
    \label{tab:gpu/vesa}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Chapter4-GPU_CLKU/res/vesa_signals.PNG}
    \caption{VESA signals - video signal represents both display enable signals}
    \label{fig:gpu/vesa_signals}
\end{figure}

\section{GPU components}

\subsection{Graphic memory}

The graphic memory has two functions. The first one is of course to store the state of all the 
pixels on the screen. This is done as discussed above by splitting the memory into four parts. One 
for each color of the Figure \ref{fig:gpu/screen_tiling} paving. Each of these sub-memories is then divided into three, one for 
each primary color. This was done this way because it is more optimal to have three memories whose 
word size is a power of two. By dividing by three, each word has 4bits while it would have had 
12bits in the case of full colors, which is not a power of 2. A fifth port with a different clock 
from the first 4 ports is also exposed. This one allows the reading of the memory tile by tile for 
the HDMI controller part of the GPU. This tile is refered to as Tile b.

The second function is to correctly direct the values in memory to the outputs when reading, and 
the values in input to the memories when writing. Indeed, depending on the editing position (address), the 
current tile belongs to one of the memories. And the memories of the other three tiles to be 
selected also depends on this position. See Figure \ref{fig:gpu/screen_tiling_cases} for the different possible configurations. 

From now on, the current tile (at the target position) will be tile 0. The one to the right of it
will be tile 1, the one below it will be tile 2 and the one below it on the right will be tile 3. 
Figure \ref{fig:gpu/tile_ids} summarizes this. Note that the colors are set by tiles. A memory word 
is therefore $4 \times 64$ = 256bits.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/tile_ids}
    \caption{Tile identifiers}
    \label{fig:gpu/tile_ids}
\end{figure}

\subsubsection*{Memory unit}

The memory units are the modules representing the groups of tiles, so there are 4 of them in the 
graphic memory. Each memory unit is composed of three Altsyncram configured in true-dualport RAM 
representing the three primary colors. True dualport means with two completely independent ports, 
the clocks are different. The module simply interfaces these three Altsyncrams. The internal 
circuit is given in Figure \ref{fig:gpu/memory_unit_in} and its module in Figure 
\ref{fig:gpu/memory_unit}. As you can see, the wren\_b and data\_b signals 
of each memory are grounded since the second port is read-only. For the rest, the signals are 
simply retransmitted. The addresses in the three internal memories are the same, since it is the
same block that is targeted each time. The words are all 256bits in size as each word contains 64 
pixels and one of their color components on 4bits. 

Now that the memory units are described, it is possible to establish the complete memory circuit.
The complete circuit is shown in Figure \ref{fig:gpu/memory_in}. It consists of a parallel 
connection of four memory units. 

Each color input of each memory unit is multiplexed between the four color inputs of the same color 
of the memory itself. The four inputs of these multiplexers are in fact the colors of each of the 
tiles used (tile 0, tile 1, tile 2 and tile 3). Then, each of the outputs of the memory are 
multiplexed from the values in memory in the different memory units. All these multiplexers ensure 
that the tiles are correctly routed, as explained above. These multiplexers are controlled by five 
signals: sw0, sw1, sw2, sw3 and swb which are respectively linked to tile 0, tile 1, tile 2, tile 3 
and tile b. The determination of the values of these switches as well as those of the addresses of 
the memory units are not displayed in the circuit so as not to make it more cumbersome.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/memory_unit}
    \caption{Memory Unit}
    \label{fig:gpu/memory_unit}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/memory_unit_in}
    \caption{Memory Unit internal circuit}
    \label{fig:gpu/memory_unit_in}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.55]{Chapter4-GPU_CLKU/res/memory_in_part1}
    \caption{Memory internal circuit}
    \label{fig:gpu/memory_in}
\end{figure}


\subsection{Mask memory}

The mask memory is identical to the CPU memory instruction except that the Altsyncram used contains 
only 256 words of 128bits. This allows to store 256 masks. The circuits are given in Figures
\ref{fig:gpu/mask_memory_in} and \ref{fig:gpu/mask_memory}. Note that if the address is equal to
255, then the mask sent to the data\_read output is a constant mask (named clear mask) which 
clears all pixels.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Chapter4-GPU_CLKU/res/mask_memory_in}
    \caption{Mask memory internal circuit}
    \label{fig:gpu/mask_memory_in}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{Chapter4-GPU_CLKU/res/mask_memory}
    \caption{Mask memory}
    \label{fig:gpu/mask_memory}
\end{figure}

\subsection{Shifter}

The objective of this module is to replicate the mask four times and to shift it in each of these 
copies so that it corresponds to the mask offset given by the user. After that, each of the copies 
can be associated with one of the four tiles loaded out of memory. This association is done in 
another module.

\subsubsection*{Shifter Unit}

This is the module that is responsible of the shifting. To do this it simply takes the signed 
offsets given in input and shifts the bits of the mask. The offsets being given in pixels and the
masks having two bits per pixel, it is necessary to multiply by two each offset. To realize an 
offset according to x, each line of the mask is shifted 2 $\times$ offset\_x while for an offset 
according to y, the whole mask is shifted of 16 $\times$ offset\_y given that there are 8 pixels 
by line. The circuit and the interface of the shifter unit are respectively given in Figures
\ref{fig:gpu/shifter_unit_in} and \ref{fig:gpu/shifter_unit}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Chapter4-GPU_CLKU/res/shifter_unit_in}
    \caption{Shifter unit internal circuit}
    \label{fig:gpu/shifter_unit_in}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{Chapter4-GPU_CLKU/res/shifter_unit}
    \caption{Shifter unit}
    \label{fig:gpu/shifter_unit}
\end{figure}

The complete shifter is just a simple paralleling of four shifters but you have to choose the right 
offsets for each shifter unit. In Figure are shown \ref{fig:gpu/shifter_offsets}
the different offsets needed to obtain the desired masks. Each offset is taken with respect to the 
upper left corner of the mask to which it is associated. off\_0 is of course equal to 
(off\_x, off\_y) since the offset is always given from the selected tile and the selected tile is 
identified by id 0. For the others, the offsets are off\_1 = (off\_x - 8, off\_y), off\_2 = 
(off\_x, off\_y - 8) and off\_3 = (off\_x - 8, off\_y - 8).

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/shifter_offsets}
    \caption{Masks offsets}
    \label{fig:gpu/shifter_offsets}
\end{figure}

The complete shifter circuit can then be established and is given in Figure \ref{fig:gpu/shifter_in}. 
Figure \ref{fig:gpu/shifter} contains the shifter interface.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/shifter_in}
    \caption{Shifter internal circuit}
    \label{fig:gpu/shifter_in}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/shifter}
    \caption{Shifter}
    \label{fig:gpu/shifter}
\end{figure}


\subsection{Mask Logic Unit (MLU)}

The MLU is simply used to modify the current value of a pixel in a tile according to the operation 
described for this pixel in the corresponding mask. This module is a kind of giant multiplexer. In 
fact, it contains a multiplexer for each primary color of each pixel and will select an input 
(the current value of the pixel, the primary color, the secondary color or the black color) 
according to the value of the mask at that position. Its operation is very simple to understand 
and its circuit impossible to draw on a page of this report. That's why the internal circuit is 
passed for this module. The interface is however given in Figure \ref{fig:gpu/mlu}.
Note that this circuit is completely combinatorial. Converning the tile buses, they are simply
made up of the three color signals of the corresponding tile.

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/mlu}
    \caption{Mask Logic Unit}
    \label{fig:gpu/mlu}
\end{figure}

\subsection{Graphic Counter (GC)}

The graphics counter is the first element fully included in the HDMI controller part of the GPU. 
It simply counts and provides several counts. Firstly, it provides the current position of the 
pixel taken into account, so cnt\_h and cnt\_v representing the horizontal and vertical position 
of the pixel. These go through all the virtual screen of the VESA, that is to say from 0 to 1087 
for cnt\_h and from 0 to 516 for cnt\_v. These counts are then used to correctly generate the 
synchronization signals of the VESA in another module. 

Then, it provides four other counters blk\_x, blk\_y, off\_x, off\_y which again give the position 
of a pixel but using this time the GPU coordinate system. It should be noted that these counters 
only count from the start of the useful screen. In other words, blk\_x and blk\_y will both be at 0 
when they reach values of cnt\_h and cnt\_v which correspond to the location of the first tile in 
memory, the one at the top left of the useful screen. And their values will continue to increase 
until the end of the VESA virtual screen.

It should be noted that the useful screen does not correspond to the entire active area of the 
VESA. As mentioned earlier, not all the space is used because of memory constraints. The useful 
screen is centered in this active region. When the counter is in the useful region of the screen, 
the in\_mem signal is high to warn that the position given by the counter corresponds to a tile 
present in memory. The range of the counters and a schematic of the positioning of the useful 
region are given in Figure \ref{fig:gpu/gc_screen}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Chapter4-GPU_CLKU/res/gc_screen}
    \caption{Counters range and useful screen}
    \label{fig:gpu/gc_screen}
\end{figure}

All these counters are implemented with the help of registers by choosing correctly the clk\_enable 
signals and the reset signals. The inner circuit without the in\_memory which is only a condition 
on the values of h\_cnt and v\_cnt is given in Figure \ref{fig:gpu/gc_in}
. The interface is also shown in Figure \ref{fig:gpu/gc}.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{Chapter4-GPU_CLKU/res/gc}
    \caption{Graphic counter}
    \label{fig:gpu/gc}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Chapter4-GPU_CLKU/res/gc_in}
    \caption{Graphic counter internal circuit}
    \label{fig:gpu/gc_in}
\end{figure}

\subsection{Synchronizer}

The synchronizer is in charge of generating the synchronization and display enable signals of the
VESA protocol. It simply looks at the values of the h\_cnt and v\_cnt signals provided by the 
graphic counter. If the values are within the ranges associated with the synchronizations or display
enable, the synchronizer sets the signal to high. As a reminder, the ranges were described in 
Figure \ref{fig:gpu/screen_vesa} and Table \ref{tab:gpu/vesa}. As the internal circuit is 
only a condition, it is not shown. The interface is shown in Figure \ref{fig:gpu/synchronizer}.  

\begin{figure}[H]
    \centering
    \includegraphics[scale=1.0]{Chapter4-GPU_CLKU/res/synchronizer}
    \caption{Synchronizer}
    \label{fig:gpu/synchronizer}
\end{figure}

\subsection{I2C HDMI Config}

This module is provided by Terasic to configure the HDMI controller present on the DE10 nano board. 
In this work, it is used as a library. That is to say, it has not been tried to understand what it 
does, what are its internal circuits. In the GPU, it is simply connected to the pins of the physical
HDMI controller as Terasic suggests in his tutorial. The interface is still provided in 
Figure \ref{fig:gpu/i2c}.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{Chapter4-GPU_CLKU/res/i2c}
    \caption{I2C HDMI Config}
    \label{fig:gpu/i2c}
\end{figure}

\subsection{Complete circuit}